p8105 Homework 2
================
Tory Lynch

#### Problem 1

##### Import CSV file and clean data

``` r
MTA_data <- read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
                     col_types = "cccddccccccciiiicccccclclcccddcc") %>%
            janitor::clean_names() %>%
            dplyr::select(line:entry, vending, ada) %>%
            mutate(entry = as.logical(ifelse(entry == "YES", TRUE, FALSE))) 

skimr::skim(MTA_data)
```

    ## Skim summary statistics
    ##  n obs: 1868 
    ##  n variables: 19 
    ## 
    ## ── Variable type:character ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##       variable missing complete    n min max empty n_unique
    ##  entrance_type       0     1868 1868   4   9     0        7
    ##           line       0     1868 1868   5  17     0       36
    ##         route1       0     1868 1868   1   2     0       24
    ##         route2     848     1020 1868   1   2     0       20
    ##         route3    1374      494 1868   1   2     0       18
    ##         route4    1547      321 1868   1   1     0       13
    ##         route5    1630      238 1868   1   1     0       12
    ##         route6    1741      127 1868   1   1     0        7
    ##         route7    1788       80 1868   1   2     0        7
    ##   station_name       0     1868 1868   4  39     0      356
    ##        vending       0     1868 1868   2   3     0        2
    ## 
    ## ── Variable type:integer ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##  variable missing complete    n mean   sd p0 p25 p50 p75 p100     hist
    ##   route10    1845       23 1868 3    0     3   3   3   3    3 ▁▁▁▇▁▁▁▁
    ##   route11    1845       23 1868 7    0     7   7   7   7    7 ▁▁▁▇▁▁▁▁
    ##    route8    1820       48 1868 2.98 1.94  1   1   4   5    5 ▇▁▁▁▁▂▁▇
    ##    route9    1840       28 1868 2.54 1.17  2   2   2   2    5 ▇▁▁▁▁▁▁▂
    ## 
    ## ── Variable type:logical ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##  variable missing complete    n mean                      count
    ##       ada       0     1868 1868 0.25 FAL: 1400, TRU: 468, NA: 0
    ##     entry       0     1868 1868 0.94 TRU: 1753, FAL: 115, NA: 0
    ## 
    ## ── Variable type:numeric ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##           variable missing complete    n   mean    sd     p0    p25    p50
    ##   station_latitude       0     1868 1868  40.73 0.07   40.58  40.69  40.73
    ##  station_longitude       0     1868 1868 -73.94 0.057 -74.03 -73.99 -73.96
    ##     p75   p100     hist
    ##   40.77  40.9  ▂▂▅▇▇▂▃▂
    ##  -73.91 -73.76 ▃▇▅▃▂▁▁▁

##### Description of dataset

The dataset contains information about all of the NYC MTA subway station lines, including the station stops, locations (latitude, longitude, cross streets) and routes served (i.e. the numbers and/or letters of the trains on each line). Many of the variables address the accessiblity of the station line; these data describe the entrance and exit type for each station, whether or not they are staffed, have metro card vending machines, and are ADA-compliant. The dataset also includes information about the station entrances (lat, long, corner position) that is separate from the station location. The data cleaning process involved restricting the dataset from 32 to 19 variables. I removed the variables that described the entrance location (lat, long, corner position), whether the stations were exit only, and if the stations were staffed. I also converted the entry variable, which identifies whether a station has an entrance, from a character to a logical variable. The dimensions of the data are 1868 by 19. The data are tidier because I arranged them in a clear format by selecting the relevant variables and by converting a variable into an easier-to-use format.

##### Questions

``` r
#Question 1
table_distinct_stations <- distinct(MTA_data) 
num_distinct_stations <- as.integer(count(table_distinct_stations))

#Question 2 
proportion_ada_compliant <- (round(sum(table_distinct_stations$ada == "TRUE") / num_distinct_stations, 3))*100

#Question 3 
prop_entry_no_vending <- (round((sum(table_distinct_stations$vending == "NO" & 
          table_distinct_stations$entry == "TRUE") /sum(table_distinct_stations$vending == "NO")), 3))*100
```

There are 684 distinct stations, of which 26.2% are ADA-compliant. Among the stations without vending, 38.5% allow entrance.

##### Reformat data

``` r
stations_name_and_route <- gather(table_distinct_stations, key = route, value = line, route1: route11) %>%
  filter(!is.na(line)) %>%
  select(-route)

stations_per_line <- stations_name_and_route %>%
  group_by(line, ada) %>%
  tally()
total_a_train <- 34+57
percent_ada_compliant <- (34 / total_a_train)*100
```

There are 91 distinct stations that serve the A line, 37.3626374% of which are ADA compliant.

#### Problem 2

##### Import Excel file and clean data

``` r
#Trashwheel data
trashwheel_data <- read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                              sheet = "Mr. Trash Wheel", 
                              range = cell_cols("A:N")) %>% 
                   janitor::clean_names() %>% 
                   filter(!is.na(dumpster)) %>% 
                   mutate(sports_balls = as.integer(round(sports_balls, 0)))

#2017 precipitation data  
precip_2017 <- read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                              sheet = "2017 Precipitation", 
                              skip = 2, 
                              col_names = c("Month", "Precip")) %>%  
               filter(!is.na(Month)) %>% 
               mutate(Year = 2017)

#2016 precipitation data 
precip_2016 <- read_excel("data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                              sheet = "2016 Precipitation", 
                              skip = 2, 
                              col_names = c("Month", "Precip")) %>%  
               filter(!is.na(Month)) %>% 
               mutate(Year = 2016)                            

#Combine precipitation data 
total_precip_data <- bind_rows(precip_2016, precip_2017) %>% 
               mutate(month = as.character(month.name[Month])) %>% 
               select(-Month)
```

``` r
skimr::skim(trashwheel_data)
```

    ## Skim summary statistics
    ##  n obs: 285 
    ##  n variables: 14 
    ## 
    ## ── Variable type:character ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##  variable missing complete   n min max empty n_unique
    ##     month       0      285 285   3   9     0       12
    ## 
    ## ── Variable type:integer ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##      variable missing complete   n  mean    sd p0 p25 p50 p75 p100
    ##  sports_balls       0      285 285 12.66 10.32  0   5   8  18   56
    ##      hist
    ##  ▇▃▂▂▁▁▁▁
    ## 
    ## ── Variable type:numeric ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##            variable missing complete   n     mean       sd      p0
    ##           chip_bags       0      285 285  1920.56   970.9   330   
    ##     cigarette_butts       0      285 285 36103.86 35615.98 1000   
    ##            dumpster       0      285 285   143       82.42    1   
    ##       glass_bottles       0      285 285    27.98    19.04    2   
    ##        grocery_bags       0      285 285  1418.87   917.94   50   
    ##       homes_powered       0      285 285    41.93    25.6     0   
    ##     plastic_bottles       0      285 285  1969.05  1053.97  210   
    ##         polystyrene       0      285 285  2320.83  1209.83  320   
    ##  volume_cubic_yards       0      285 285    15.58     1.79    7   
    ##         weight_tons       0      285 285     3.28     0.78    0.96
    ##                year       0      285 285  2016.08     1.4  2014   
    ##       p25      p50      p75      p100     hist
    ##   1040     1840     2660      5085    ▇▇▆▇▆▃▁▁
    ##  12000    26000    46000    310000    ▇▂▁▁▁▁▁▁
    ##     72      143      214       285    ▇▇▇▇▇▇▇▇
    ##     12       26       42       110    ▇▇▆▃▂▁▁▁
    ##    650     1240     2130      3750    ▇▇▅▅▅▃▂▁
    ##     30.5     50.67    60.33     93.67 ▇▁▂▅▇▆▂▁
    ##    980     1930     2670      5960    ▇▇▇▇▃▂▁▁
    ##   1250     2250     3150      6540    ▇▇▇▇▅▂▁▁
    ##     15       15       17        20    ▁▁▁▁▇▁▃▁
    ##      2.73     3.33     3.83      5.62 ▁▂▅▇▇▅▁▁
    ##   2015     2016     2017      2018    ▅▇▁▆▁▆▁▇
    ## 
    ## ── Variable type:POSIXct ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##  variable missing complete   n        min        max     median n_unique
    ##      date       0      285 285 2014-05-16 2018-07-28 2016-07-13      186

``` r
skimr::skim(total_precip_data)
```

    ## Skim summary statistics
    ##  n obs: 24 
    ##  n variables: 3 
    ## 
    ## ── Variable type:character ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##  variable missing complete  n min max empty n_unique
    ##     month       0       24 24   3   9     0       12
    ## 
    ## ── Variable type:numeric ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
    ##  variable missing complete  n    mean   sd   p0     p25     p50     p75
    ##    Precip       0       24 24    3.04 1.96    0    1.47    2.77    4.46
    ##      Year       0       24 24 2016.5  0.51 2016 2016    2016.5  2017   
    ##     p100     hist
    ##     7.09 ▅▆▇▃▅▅▅▂
    ##  2017    ▇▁▁▁▁▁▁▇

``` r
total_2017_precip <- total_precip_data %>% 
  group_by(Year) %>% 
  tally(Precip)

total_precip_data <- total_precip_data %>% 
  mutate()

sportsballs_by_year <- trashwheel_data %>% 
  group_by(year) %>% 
  summarise(n = median(sports_balls))
```

#### Problem 3

##### Import data

``` r
 data("brfss_smart2010")
 head(brfss_smart2010)
```

    ## # A tibble: 6 x 23
    ##    Year Locationabbr Locationdesc  Class  Topic   Question       Response 
    ##   <int> <chr>        <chr>         <chr>  <chr>   <chr>          <chr>    
    ## 1  2010 AL           AL - Jeffers… Healt… Overal… How is your g… Excellent
    ## 2  2010 AL           AL - Jeffers… Healt… Overal… How is your g… Very good
    ## 3  2010 AL           AL - Jeffers… Healt… Overal… How is your g… Good     
    ## 4  2010 AL           AL - Jeffers… Healt… Overal… How is your g… Fair     
    ## 5  2010 AL           AL - Jeffers… Healt… Overal… How is your g… Poor     
    ## 6  2010 AL           AL - Jeffers… Healt… Fair o… Health Status… Good or …
    ## # ... with 16 more variables: Sample_Size <int>, Data_value <dbl>,
    ## #   Confidence_limit_Low <dbl>, Confidence_limit_High <dbl>,
    ## #   Display_order <int>, Data_value_unit <chr>, Data_value_type <chr>,
    ## #   Data_Value_Footnote_Symbol <chr>, Data_Value_Footnote <chr>,
    ## #   DataSource <chr>, ClassId <chr>, TopicId <chr>, LocationID <chr>,
    ## #   QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

``` r
 brfss_data <- filter(brfss_smart2010, Topic == "Overall Health") %>% 
   janitor::clean_names() %>% 
   dplyr::select(-(class:question), -(sample_size), -(confidence_limit_low:geo_location)) %>% 
   spread(key = response, data_value) %>% 
   janitor::clean_names() %>% 
   mutate(proportion_excellent_or_good = (excellent + very_good)/(excellent+very_good+good+fair+poor))
```
